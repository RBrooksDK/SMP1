<h2 align="center">10 Markov Chains</h2>

**Material:**

[Recap notes](https://drive.google.com/file/d/1YrRNbEuI3CzXbju8-dNLD3SJB1Nadbum/view?usp=sharing)

[Session notes](https://drive.google.com/file/d/1wlPT8WzlZ91CqzwnlmhFfryKuElfnfoD/view?usp=sharing)

[Session material](https://viaucdk-my.sharepoint.com/:f:/g/personal/rib_viauc_dk/EuqNIuAYAltDmfXlB9l-DpMBTP5g7G1XrHFCqcXim9OfNQ?e=pbUO6r)

Session from 20/21: [SMP 10](https://youtu.be/18PY0ogn5yI)

## Topics

Markov chains are a mathematical framework used to model systems that change over time, such as the weather or the stock market. The key feature of a Markov chain is that it assumes that the future state of the system depends only on its current state, and not on any previous states. This is known as the Markov property. Markov chains are defined by a set of states, a transition matrix that describes the probabilities of moving from one state to another, and an initial state. The long-term behavior of a Markov chain can be analyzed using techniques such as finding the stationary distribution or calculating expected values. Markov chains are used in a wide range of applications, including computer science, physics, finance, and biology, among others.

- Markov property: The assumption that the future state of a system depends only on its current state, and not on any previous states.
- State: A possible condition or configuration of the system being modeled.
- Transition matrix: A matrix that describes the probabilities of moving from one state to another.
- Stationary distribution: The long-term distribution of states that a Markov chain approaches over time.
- Expected value: The average value that a variable takes over many iterations of the Markov chain.

## Problems to be worked on in class:

Do Problems 10 and the Wiseflow exam cases covering the final topics.



